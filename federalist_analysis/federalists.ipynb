{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "Using spaCy\n",
    "- See the deep dive guides on https://spacy.io/docs/usage/tutorials\n",
    "- In particular: https://github.com/JonathanReeve/advanced-text-analysis-workshop-2017\n",
    "\n",
    "General resources on NLP:\n",
    "- Awesome curated list of resources: https://github.com/keon/awesome-nlp\n",
    "\n",
    "Splitting up the text in chapters: https://github.com/JonathanReeve/chapterize\n",
    "\n",
    "Possibly relevant, higher level library for spaCy interaction: https://github.com/chartbeat-labs/textacy\n",
    "\n",
    "\n",
    "\n",
    "## Content analysis\n",
    "Frequency things to look at:\n",
    "- Words with interesting presence in corpus, to get a first impression.\n",
    "- Presence of select terms based on that across the corpus.\n",
    "- Probability measures of custom terms across the corpus.\n",
    "- Chunk corpus into the separate essays and look at dispersion of frequencies.\n",
    "- Visualizations \n",
    "- Comparisons with a reference corpus\n",
    "\n",
    "Ngrams, collocations\n",
    "\n",
    "Topical analysis:\n",
    "- Most prevalent verbs and their most prevalent valency actants.\n",
    "- Topic modelling\n",
    "\n",
    "## Linguistic analysis\n",
    "\n",
    "- Syntactical tendencies in the whole corpus and in separate texts.\n",
    "- Stylometric analysis and author identification/dispersion across the texts. Correspondence with known authorships?\n",
    "- Dominant syntactical structures?\n",
    "- Sentence length (compared to reference corpus, modern English).\n",
    "- Average nesting depth.\n",
    "\n",
    "## Cases\n",
    "\n",
    "Attribution dispute, cf. the [wikipedia section](https://en.wikipedia.org/wiki/The_Federalist_Papers#Disputed_essays):\n",
    "- Can we replicate some of the already published studies?\n",
    "- Supplement the results by other analyses? Contradict, support?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to prepare our corpus. In this case we have a very small corpus, so it would be a simple task to download the file manually through a web browser. But it is incredibly useful to be able to do it programmatically in stead. To do that we will use some functionality from the built-in Python library `urllib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from urllib import request\n",
    "import os\n",
    "\n",
    "def download_to_file(url, directory='./data', filename='download.txt'):\n",
    "    web_response = request.urlopen(url)\n",
    "    web_content = web_response.read().decode('utf-8')\n",
    "    \n",
    "    if not os.path.isdir(directory):\n",
    "        os.mkdir(directory)\n",
    "    full_filename = os.path.join(directory, filename)\n",
    "    \n",
    "    with open(full_filename, mode='w', encoding='utf-8') as f:\n",
    "        f.write(web_content)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function downloads the content of the `url` into a file. If none of the two keyword arguments are specified, the file will be saved in the current working directory with the filename `download.txt`. \n",
    "\n",
    "*The Federalist Papers* can be downloaded as a single plain text file from [Project Gutenberg](www.gutenberg.org). The specific address is: https://www.gutenberg.org/cache/epub/1404/pg1404.txt. \n",
    "\n",
    "So let's download that: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "federalist_file = download_to_file('https://www.gutenberg.org/cache/epub/1404/pg1404.txt', filename='federalist.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import spacy\n",
    "from spacy.tokens.doc import Doc\n",
    "from spacy.tokens.token import Token\n",
    "from spacy.tokens.span import Span"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the English language model before moving on with `spacy download en`. Then we can load the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we initialize our document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_doc(in_file_path) -> Doc:\n",
    "    with open(in_file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "        doc = nlp(text)\n",
    "        print('Teksten indeholder {} ord'.format(len(list(doc))))\n",
    "\n",
    "        return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teksten indeholder 236196 ord\n",
      "CPU times: user 10.9 s, sys: 152 ms, total: 11.1 s\n",
      "Wall time: 11.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "doc = make_doc(federalist_file.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_tokens(doc, lemma_, pos_=None):\n",
    "    return [token for token in doc\n",
    "            if token.lemma_ == lemma_ and (pos_ is None or token.pos_ == pos_)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tokens(*lemma):\n",
    "    words = {}\n",
    "    for lemma in lemma:\n",
    "        words[lemma] = len(find_tokens(doc, lemma))\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'honor': 21,\n",
       " 'peace': 113,\n",
       " 'state': 1003,\n",
       " 'union': 377,\n",
       " 'unite': 39,\n",
       " 'war': 153}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_tokens('union', 'state', 'unite', 'honor', 'war', 'peace')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from typing import List, Tuple\n",
    "keywords = Counter()\n",
    "\n",
    "# On probability: The lower the value, the less likely is the word to occur â‰ˆ the more significant \n",
    "# is its occurence. (gleaned from https://github.com/explosion/spaCy/commit/ff9ff6f3fa1fe15191233796e669028a31936dee)\n",
    "\n",
    "def most_significant_words(doc: Doc, count: int = 35,\n",
    "                           probability: int = -8) -> List[Tuple[str, int]]:\n",
    "    for chunk in doc:\n",
    "        # probablity value -8 is arbitrarily selected threshold\n",
    "        if nlp.vocab[chunk.lemma_].prob < probability:\n",
    "            keywords[chunk.lemma_] += 1\n",
    "\n",
    "    return keywords.most_common(count)\n",
    "\n",
    "\n",
    "def most_significant_verbs(doc: Doc, count: int = 35,\n",
    "                           probability: int = -8) -> List[Tuple[str, int]]:\n",
    "    for token in doc:\n",
    "        if token.pos_ == 'VERB' and nlp.vocab[token.lemma_].prob < probability:\n",
    "            keywords[token.lemma_] += 1\n",
    "\n",
    "    return keywords.most_common(count)\n",
    "\n",
    "\n",
    "def most_significant_noun_phrases(doc: Doc, count: int = 35,\n",
    "                                  probability: int = -8) -> List[Tuple[str, int]]:\n",
    "    for chunk in doc.noun_chunks:\n",
    "        if nlp.vocab[chunk.lemma_].prob < probability:\n",
    "            keywords[chunk.lemma_] += 1\n",
    "\n",
    "    return keywords.most_common(count)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('-PRON-', 11608),\n",
      " ('the people', 1008),\n",
      " ('the union', 552),\n",
      " ('the constitution', 434),\n",
      " ('the states', 422),\n",
      " ('the power', 418),\n",
      " ('the government', 402),\n",
      " ('the state', 352),\n",
      " ('the united states', 332),\n",
      " ('the convention', 280)]\n",
      "[('-PRON-', 11608),\n",
      " ('the people', 1008),\n",
      " ('the union', 552),\n",
      " ('the constitution', 434),\n",
      " ('the states', 422),\n",
      " ('the power', 418),\n",
      " ('the government', 402),\n",
      " ('the state', 352),\n",
      " ('the united states', 332),\n",
      " ('the convention', 280)]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(most_significant_noun_phrases(doc, probability=-10, count=10))\n",
    "pprint(most_significant_noun_phrases(doc, probability=-20, count=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ought', 275),\n",
      " ('shall', 254),\n",
      " ('find', 186),\n",
      " ('propose', 158),\n",
      " ('appear', 154),\n",
      " ('require', 145),\n",
      " ('consider', 143),\n",
      " ('give', 126),\n",
      " ('form', 122),\n",
      " ('establish', 120)]\n"
     ]
    }
   ],
   "source": [
    "pprint(most_significant_verbs(doc, probability=0, count=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x10b31e630>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAD8CAYAAACGsIhGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10b6e1c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# How are the probabilities distributed in the text?\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "probabilities = [word.prob for word in doc]\n",
    "pd.Series(probabilities).hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "From the above, it looks like the probability measure is not based on the whole corpus, but on a smaller context. Notice how the count differs based on the probability limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
